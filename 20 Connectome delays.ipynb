{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ad0d3ea",
   "metadata": {},
   "source": [
    "How are we handling connectome with delays in Jax? tl;dr jump down to bottom, the forward and backwards passes are\n",
    "```python\n",
    "def fwd(buffer):\n",
    "    return jnp.sum(weights*buffer[ns,lengths], axis=1)\n",
    "\n",
    "def vjp(g,buffer):\n",
    "    gb = jnp.tile(g[:,None],(1,nn)) # rev of sum(a, axis=1)\n",
    "    return jnp.zeros_like(buffer).at[ns,lengths.T].add(weights.T*gb)\n",
    "```\n",
    "\n",
    "In practice the g_buffer needs to be reused & accumulate gradients from multiple time steps into same buffer otherwise perf will be terrible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1ff65e2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-20T09:36:35.983367Z",
     "start_time": "2022-12-20T09:36:35.646853Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%pylab is deprecated, use %matplotlib inline and import the required libraries.\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import numpy as np\n",
    "import jax\n",
    "import jax.numpy as jnp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "bd5ee5d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-20T16:58:43.919651Z",
     "start_time": "2022-12-20T16:58:43.905076Z"
    }
   },
   "outputs": [],
   "source": [
    "keys = jax.random.split(jax.random.PRNGKey(0), 10)\n",
    "nn = 84\n",
    "weights = jax.random.normal (keys[0], (nn, nn))\n",
    "lengths = jax.random.randint(keys[1], (nn, nn), 0, 255)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea744dd",
   "metadata": {},
   "source": [
    "Here's our buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "267e36fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-20T09:36:37.650053Z",
     "start_time": "2022-12-20T09:36:37.518540Z"
    }
   },
   "outputs": [],
   "source": [
    "buffer = jax.random.normal(keys[2], (nn, lengths.max()+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404e7c4c",
   "metadata": {},
   "source": [
    "How to do this in jax?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0299b603",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-20T09:36:44.729939Z",
     "start_time": "2022-12-20T09:36:38.748562Z"
    }
   },
   "outputs": [],
   "source": [
    "# don't bother with @jax.jit\n",
    "def cfun1(weights, lengths, buffer):\n",
    "    nn = weights.shape[0]\n",
    "    aff = []\n",
    "    for i in range(nn):\n",
    "        acc = 0\n",
    "        for j in range(nn):\n",
    "            acc += weights[i,j] * buffer[j, lengths[i,j]]\n",
    "        aff.append(acc)\n",
    "    return jnp.array(aff)\n",
    "\n",
    "aff1 = cfun1(weights, lengths, buffer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b27bcf2",
   "metadata": {},
   "source": [
    "This is slow, and JIT compiling will unroll the nested loops completely, making this hazardous except that it's obviously correct with the explicit loop.\n",
    "\n",
    "Numba is good with explicit loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e10c3bfe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-20T09:37:59.665053Z",
     "start_time": "2022-12-20T09:37:54.749866Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.89 µs ± 22.3 ns per loop (mean ± std. dev. of 7 runs, 100,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "import numba as nb\n",
    "\n",
    "@nb.njit\n",
    "def cfun2(aff, weights, lengths, buffer):\n",
    "    nn = weights.shape[0]\n",
    "    for i in range(nn):\n",
    "        acc = nb.float32(0)\n",
    "        for j in range(nn):\n",
    "            acc += weights[i,j] * buffer[j, lengths[i,j]]\n",
    "        aff[i] = acc  \n",
    "\n",
    "aff2 = np.zeros_like(aff1)\n",
    "npargs = [np.array(_) for _ in (weights, lengths, buffer)]\n",
    "cfun2(aff2, *npargs)\n",
    "np.testing.assert_allclose(aff1, aff2)\n",
    "%timeit cfun2(aff2, *npargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0619b26e",
   "metadata": {},
   "source": [
    "So that's a nicer baseline to start with, too bad Numba doesn't autodiff.\n",
    "\n",
    "Before vectorizing, let's try a `scan` w/ Jax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3443c9fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-20T09:55:01.721230Z",
     "start_time": "2022-12-20T09:54:51.863656Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.1 µs ± 190 ns per loop (mean ± std. dev. of 7 runs, 100,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "def cfun3(weights, lengths, buffer):\n",
    "    js = jnp.r_[:weights.shape[0]]\n",
    "    def do_ij(acc, jwl):\n",
    "        j,w,l = jwl\n",
    "        acc = acc + w * buffer[j, l]\n",
    "        return acc, j\n",
    "    def do_i(_, i):\n",
    "        return _, jax.lax.scan(do_ij, 0.0, (js,weights[i],lengths[i]))[0]\n",
    "    _, aff = jax.lax.scan(do_i, 0, js)\n",
    "    return aff\n",
    "\n",
    "cfun3j = jax.jit(cfun3)\n",
    "aff3 = cfun3j(weights, lengths, buffer)\n",
    "np.testing.assert_allclose(aff1, aff3, 1e-5, 1e-5)\n",
    "%timeit cfun3j(weights, lengths, buffer).block_until_ready()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca048638",
   "metadata": {},
   "source": [
    "This has a nicely functional flavor to it and is certainly ok speed wise, assuming Jax transforms apply nicely.  How does it do with batching?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2b2946d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-20T09:55:59.364713Z",
     "start_time": "2022-12-20T09:55:18.391337Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.4 µs ± 14.4 ns per loop (mean ± std. dev. of 7 runs, 100,000 loops each)\n",
      "12.1 µs ± 50.4 ns per loop (mean ± std. dev. of 7 runs, 100,000 loops each)\n",
      "54.6 µs ± 24.8 ns per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n",
      "85.7 µs ± 64.3 ns per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n",
      "127 µs ± 532 ns per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "cfun3_batch = jax.jit(jax.vmap(lambda b: cfun3(weights, lengths, b)))\n",
    "for batch_size in [1, 2, 4, 8, 16]:\n",
    "    buffer_batch = jax.random.normal(keys[2], (batch_size, nn, lengths.max()+1))\n",
    "    cfun3_batch(buffer_batch)\n",
    "    %timeit cfun3_batch(buffer_batch).block_until_ready()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a64776",
   "metadata": {},
   "source": [
    "This isn't quite what we want: if batches are stride 1, then because of random memory access, extra batches should be +/- free.  Maybe `jax.vmap` can do that if we ask nicely?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "31ae5903",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-20T10:01:38.245141Z",
     "start_time": "2022-12-20T10:00:53.086934Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.4 µs ± 24.7 ns per loop (mean ± std. dev. of 7 runs, 100,000 loops each)\n",
      "17.7 µs ± 87.2 ns per loop (mean ± std. dev. of 7 runs, 100,000 loops each)\n",
      "72.9 µs ± 25.6 ns per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n",
      "159 µs ± 36.2 ns per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n",
      "263 µs ± 728 ns per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "cfun3_batch = jax.jit(jax.vmap(lambda b: cfun3(weights, lengths, b), 2))\n",
    "for batch_size in [1, 2, 4, 8, 16]:\n",
    "    buffer_batch = jax.random.normal(keys[2], (nn, lengths.max()+1, batch_size))\n",
    "    cfun3_batch(buffer_batch)\n",
    "    %timeit cfun3_batch(buffer_batch).block_until_ready()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7317870",
   "metadata": {},
   "source": [
    "Nope! Compare with handwritten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5de68336",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-20T10:07:43.270690Z",
     "start_time": "2022-12-20T10:06:56.765246Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 µs ± 54 ns per loop (mean ± std. dev. of 7 runs, 100,000 loops each)\n",
      "12.2 µs ± 21.8 ns per loop (mean ± std. dev. of 7 runs, 100,000 loops each)\n",
      "12.3 µs ± 72.1 ns per loop (mean ± std. dev. of 7 runs, 100,000 loops each)\n",
      "39.9 µs ± 40.3 ns per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n",
      "55.3 µs ± 86.6 ns per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n",
      "109 µs ± 418 ns per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "@jax.jit\n",
    "def cfun3b(weights, lengths, buffer_batch):\n",
    "    js = jnp.r_[:weights.shape[0]]\n",
    "    batch_zero = jnp.zeros((buffer_batch.shape[-1],))\n",
    "    def do_ij(acc, jwl):\n",
    "        j,w,l = jwl\n",
    "        acc = acc + w * buffer_batch[j, l]\n",
    "        return acc, j\n",
    "    def do_i(_, i):\n",
    "        return _, jax.lax.scan(do_ij, batch_zero, (js,weights[i],lengths[i]))[0]\n",
    "    _, aff = jax.lax.scan(do_i, 0, js)\n",
    "    return aff\n",
    "\n",
    "for batch_size in [1, 2, 4, 8, 16, 128]:\n",
    "    buffer_batch = jax.random.normal(keys[2], (nn, lengths.max()+1, batch_size))\n",
    "    cfun3b(weights, lengths, buffer_batch)\n",
    "    %timeit cfun3b(weights, lengths, buffer_batch).block_until_ready()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b91b4e",
   "metadata": {},
   "source": [
    "That's more like it: we get a batch of 4 for the price of 1, batch of 128 for price of 10, and should scale further on wide lane hardware like GPU.  Tbh, it's not much harder to read/write: we just changed the initial value for the inner scan.\n",
    "\n",
    "Seems like just a neat trick until inference on long time series where we will make heavy use of batching over time windows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78abc8b",
   "metadata": {},
   "source": [
    "## autodiff\n",
    "\n",
    "How well does autodiff work with this?\n",
    "\n",
    "Start with a loss:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ca61f945",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-20T10:13:33.111895Z",
     "start_time": "2022-12-20T10:13:33.072049Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Array(0., dtype=float32), Array(1110308.4, dtype=float32))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "affb = cfun3b(weights, lengths, buffer_batch)\n",
    "\n",
    "def loss(bb_hat):\n",
    "    return jnp.sum((affb - cfun3b(weights, lengths, bb_hat))**2)\n",
    "\n",
    "loss(buffer_batch), loss(buffer_batch + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731f38fd",
   "metadata": {},
   "source": [
    "now grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "74845561",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-20T10:15:07.314210Z",
     "start_time": "2022-12-20T10:15:03.329653Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46.7 ms ± 1.6 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "g_loss = jax.jit(jax.grad(loss))\n",
    "g_loss(buffer_batch + 1)\n",
    "%timeit g_loss(buffer_batch + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9381bf02",
   "metadata": {},
   "source": [
    "oops that's slow!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f7e26593",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-20T10:19:20.519586Z",
     "start_time": "2022-12-20T10:17:49.402910Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.9 µs ± 12.5 ns per loop (mean ± std. dev. of 7 runs, 100,000 loops each)\n",
      "959 µs ± 171 ns per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n",
      "12.2 µs ± 34.3 ns per loop (mean ± std. dev. of 7 runs, 100,000 loops each)\n",
      "1.33 ms ± 10.6 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n",
      "12.3 µs ± 2.26 ns per loop (mean ± std. dev. of 7 runs, 100,000 loops each)\n",
      "3.77 ms ± 4.21 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "39.7 µs ± 18.8 ns per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n",
      "1.88 ms ± 14.4 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n",
      "55.6 µs ± 483 ns per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n",
      "4.61 ms ± 82.1 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "109 µs ± 28.1 ns per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n",
      "45.5 ms ± 271 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "for batch_size in [1, 2, 4, 8, 16, 128]:\n",
    "    buffer_batch = jax.random.normal(keys[2], (nn, lengths.max()+1, batch_size))\n",
    "    affb = cfun3b(weights, lengths, buffer_batch)\n",
    "    def loss(bb_hat):\n",
    "        return jnp.sum((affb - cfun3b(weights, lengths, bb_hat))**2)\n",
    "    g_loss = jax.jit(jax.grad(loss))\n",
    "    g_loss(buffer_batch + 1)\n",
    "    %timeit cfun3b(weights, lengths, buffer_batch).block_until_ready()\n",
    "    %timeit g_loss(buffer_batch + 1).block_until_ready()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13724c6",
   "metadata": {},
   "source": [
    "Vectorizing the loop makes the code simpler but not better vjp perf:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "403efdb4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-20T12:27:22.430680Z",
     "start_time": "2022-12-20T12:26:56.919581Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.9 µs ± 58.5 ns per loop (mean ± std. dev. of 7 runs, 100,000 loops each)\n",
      "1.93 ms ± 1.64 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "@jax.jit\n",
    "def cfun4(weights, lengths, buffer):\n",
    "    def do_i(_, wl):\n",
    "        w, l = wl\n",
    "        return _, w @ buffer[jnp.r_[:nn], l]\n",
    "    return jax.lax.scan(do_i, 0, (weights, lengths))[1]\n",
    "\n",
    "aff4 = cfun4(weights, lengths, buffer)\n",
    "np.testing.assert_allclose(aff1, aff4, 1e-5, 1e-5)\n",
    "%timeit cfun4(weights, lengths, buffer)\n",
    "\n",
    "gl = jax.grad(lambda b: jnp.sum((aff4 - cfun4(weights, lengths, b))**2))\n",
    "gl(buffer+1)\n",
    "%timeit gl(buffer+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd621e5f",
   "metadata": {},
   "source": [
    "## backwards by hand\n",
    "\n",
    "the backwards pass is provided by a vector-Jacobian product function or VJP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7a237a0a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-20T11:11:22.550274Z",
     "start_time": "2022-12-20T11:11:16.600934Z"
    }
   },
   "outputs": [],
   "source": [
    "def cfun1(weights, lengths, buffer):\n",
    "    nn = weights.shape[0]\n",
    "    aff = []\n",
    "    for i in range(nn):\n",
    "        acc = 0\n",
    "        for j in range(nn):\n",
    "            acc += weights[i,j] * buffer[j, lengths[i,j]]\n",
    "        aff.append(acc)\n",
    "    return jnp.array(aff)\n",
    "\n",
    "aff1 = cfun1(weights, lengths, buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "0b147581",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-20T12:40:42.897059Z",
     "start_time": "2022-12-20T12:40:42.795863Z"
    }
   },
   "outputs": [],
   "source": [
    "import numba \n",
    "np_buffer = np.array(buffer)\n",
    "@numba.jit\n",
    "def vjp_cfun1(g_aff, weights, lengths):\n",
    "    # return g_buffer\n",
    "    g_buffer = np.zeros_like(np_buffer)\n",
    "    for i in range(nn):\n",
    "        for j in range(nn):\n",
    "            g_buffer[j, lengths[i,j]] += 1 #g_aff[i]*weights[i,j]/nn\n",
    "    return g_buffer\n",
    "\n",
    "g_aff1 = np.ones(nn)\n",
    "g_buf1 = vjp_cfun1(g_aff1, np.array(weights), np.array(lengths))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c69ec3",
   "metadata": {},
   "source": [
    "So the perf is not dissimilar from before, just has random writes *but see below the result is wrong*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b85188",
   "metadata": {},
   "source": [
    "- [ ] check this against the Jax version\n",
    "- [x] check perf in Numba\n",
    "- [ ] how to get that random write pattern in Jax?\n",
    "- [ ] reorganize vjp loops for a random read for a clean scan scan structure?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c8839b",
   "metadata": {},
   "source": [
    "How can we get an equivalent function in Jax?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9a999c39",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-20T12:15:07.705024Z",
     "start_time": "2022-12-20T12:15:07.519794Z"
    }
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "\nNot equal to tolerance rtol=1e-07, atol=0\n\nMismatched elements: 10318 / 21420 (48.2%)\nMax absolute difference: 5.1995068\nMax relative difference: 40.262993\n x: array([[ 0.      ,  0.      ,  0.      , ...,  0.      , -0.010414,\n         0.007804],\n       [ 0.029223, -0.014523,  0.      , ...,  0.      ,  0.      ,...\n y: array([[ 0.273139,  0.491836,  0.      , ...,  0.      ,  0.      ,\n        -0.66439 ],\n       [ 0.      , -1.219954,  0.      , ...,  1.246804,  0.      ,...",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[77], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m g_aff3 \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39mones(nn)\n\u001b[1;32m      6\u001b[0m g_buf3 \u001b[38;5;241m=\u001b[39m vjp_cfun3(g_aff3, weights, lengths)\n\u001b[0;32m----> 7\u001b[0m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtesting\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massert_allclose\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg_buf1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mg_buf3\u001b[49m\u001b[43m)\u001b[49m\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/nfjax-Y-MGz7Lr/lib/python3.10/site-packages/numpy/testing/_private/utils.py:844\u001b[0m, in \u001b[0;36massert_array_compare\u001b[0;34m(comparison, x, y, err_msg, verbose, header, precision, equal_nan, equal_inf)\u001b[0m\n\u001b[1;32m    840\u001b[0m         err_msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(remarks)\n\u001b[1;32m    841\u001b[0m         msg \u001b[38;5;241m=\u001b[39m build_err_msg([ox, oy], err_msg,\n\u001b[1;32m    842\u001b[0m                             verbose\u001b[38;5;241m=\u001b[39mverbose, header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[1;32m    843\u001b[0m                             names\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m), precision\u001b[38;5;241m=\u001b[39mprecision)\n\u001b[0;32m--> 844\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(msg)\n\u001b[1;32m    845\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[1;32m    846\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtraceback\u001b[39;00m\n",
      "\u001b[0;31mAssertionError\u001b[0m: \nNot equal to tolerance rtol=1e-07, atol=0\n\nMismatched elements: 10318 / 21420 (48.2%)\nMax absolute difference: 5.1995068\nMax relative difference: 40.262993\n x: array([[ 0.      ,  0.      ,  0.      , ...,  0.      , -0.010414,\n         0.007804],\n       [ 0.029223, -0.014523,  0.      , ...,  0.      ,  0.      ,...\n y: array([[ 0.273139,  0.491836,  0.      , ...,  0.      ,  0.      ,\n        -0.66439 ],\n       [ 0.      , -1.219954,  0.      , ...,  1.246804,  0.      ,..."
     ]
    }
   ],
   "source": [
    "@jax.jit\n",
    "def vjp_cfun3(g_aff, weights, lengths):\n",
    "    return g_aff @ jax.jacrev(lambda b: cfun3(weights,lengths,b))(buffer)\n",
    "\n",
    "g_aff3 = jnp.ones(nn)\n",
    "g_buf3 = vjp_cfun3(g_aff3, weights, lengths)\n",
    "np.testing.assert_allclose(g_buf1, g_buf3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac299192",
   "metadata": {},
   "source": [
    "Let's try a simpler problem, just one afferent value,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "587a49d2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-20T12:22:40.700650Z",
     "start_time": "2022-12-20T12:22:40.655425Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Array(7.187064, dtype=float32), Array(7.187065, dtype=float32))"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights[0]@buffer[jnp.r_[:nn],lengths[0]], aff1[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29cdd21b",
   "metadata": {},
   "source": [
    "From this we can see that the single value of `g_aff1[0]` requires writes to, potentially, any elements of `g_buffer`: one per row at `g_buffer[i, length[0,i]]`.  Can't we invert this by indexing into `g_aff1`? Not really.. we need an efficient way to create a sparse output.  Maybe we can generate a sparse matrix directly?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "108b1e35",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-20T12:56:00.377521Z",
     "start_time": "2022-12-20T12:56:00.353731Z"
    }
   },
   "outputs": [],
   "source": [
    "def cfun5i(weights, lengths, buffer, i):\n",
    "    return jnp.dot(jnp.ones(nn), buffer[jnp.r_[:nn],lengths[i]])\n",
    "\n",
    "g = jax.grad(lambda b: jnp.sum(cfun5i(weights, lengths, b, 0)**2))(buffer)\n",
    "\n",
    "np.testing.assert_allclose(jnp.argwhere(g>0), jnp.c_[jnp.r_[:nn], lengths[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "9fa1d773",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-20T12:58:17.406129Z",
     "start_time": "2022-12-20T12:58:17.401535Z"
    }
   },
   "outputs": [],
   "source": [
    "g2 = np.zeros_like(g)\n",
    "g2[np.r_[:nn],lengths[0]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "cf6df70a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-20T12:59:50.064064Z",
     "start_time": "2022-12-20T12:59:50.059859Z"
    }
   },
   "outputs": [],
   "source": [
    "np.testing.assert_allclose(g>0, g2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b5bce1",
   "metadata": {},
   "source": [
    "So it looks like it's pretty simple and could be expressed tensor wise just as a sequence of increments with the `new_jax_array = jax_array.at[::2, 3:].add(7.)` syntax. Or even simply, we tell Jax to compute these in single array op so hopefully it behaves correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "ba861d8f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-20T14:08:23.497824Z",
     "start_time": "2022-12-20T14:08:03.797784Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.1 µs ± 74.9 ns per loop (mean ± std. dev. of 7 runs, 100,000 loops each)\n",
      "1.1 ms ± 4.56 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "@jax.jit\n",
    "def cfun5(weights, lengths, buffer):\n",
    "    return jnp.sum(weights*buffer[jnp.tile(jnp.arange(nn),(nn,1)),lengths], axis=1)\n",
    "\n",
    "aff5 = cfun5(weights, lengths, buffer)\n",
    "np.testing.assert_allclose(aff5, aff1, 1e-5, 1e-5)\n",
    "%timeit cfun5(weights, lengths, buffer).block_until_ready()\n",
    "\n",
    "gl = jax.grad(lambda b: jnp.sum((aff5 - cfun5(weights, lengths, b))**2))\n",
    "gl(buffer+1)\n",
    "%timeit gl(buffer+1).block_until_ready()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aebb62df",
   "metadata": {},
   "source": [
    "Still a no go.. let's check the jac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "387d0e34",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-20T14:09:56.266681Z",
     "start_time": "2022-12-20T14:09:56.198041Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(84, 84, 255)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "J = jax.jacrev(lambda b: cfun5(weights, lengths, b))(buffer)\n",
    "J.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "da5499b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-20T14:23:44.073157Z",
     "start_time": "2022-12-20T14:23:43.992940Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(84,)\n"
     ]
    }
   ],
   "source": [
    "def myJ():\n",
    "    Ji = np.zeros((nn, nn, 255))\n",
    "    for i in range(nn):\n",
    "        Ji[i,np.r_[:nn],lengths[i]] += weights[i]\n",
    "    return Ji\n",
    "    \n",
    "assert np.allclose(J, myJ())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "fee91cf7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-20T14:26:43.803793Z",
     "start_time": "2022-12-20T14:26:43.740882Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(84, 84, 255)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ji = np.zeros((nn, nn, 255))\n",
    "nc, nr = np.c_[:nn], np.r_[:nn]\n",
    "Ji[nc, nr, lengths] += weights\n",
    "np.testing.assert_allclose(J, Ji)\n",
    "Ji.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd20fed",
   "metadata": {},
   "source": [
    "In the linear case, this can be static,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "79166912",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-20T14:28:16.382640Z",
     "start_time": "2022-12-20T14:28:07.663785Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105 µs ± 101 ns per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "@jax.jit\n",
    "def revcfun5(g):\n",
    "    return jnp.dot(g, Ji)\n",
    "\n",
    "revcfun5(g_aff1)\n",
    "%timeit revcfun5(g_aff1).block_until_ready()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5cb558c",
   "metadata": {},
   "source": [
    "but in general we'd need to eval in the loop for an existing buffer e.g."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e841c341",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def revcfun6(g_aff, g_buffer):\n",
    "    g_buffer.at[nc, nr,]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9b78f0",
   "metadata": {},
   "source": [
    "but the explicit Jacobian is memory expensive.  Can we do just the VJP?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "67d87ef8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-20T14:41:24.125000Z",
     "start_time": "2022-12-20T14:41:21.752705Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.          0.          0.         ...  0.         -0.874768\n",
      "   0.6555433 ]\n",
      " [ 2.4547248  -1.2199535   0.         ...  0.          0.\n",
      "  -1.0467068 ]\n",
      " [ 0.          0.6704424   0.         ...  0.          0.\n",
      "   0.        ]\n",
      " ...\n",
      " [ 0.35021114  0.          0.         ...  0.09017821  0.\n",
      "   0.        ]\n",
      " [ 0.          0.          0.9938805  ... -0.4928876   0.\n",
      "   0.        ]\n",
      " [ 0.          0.          0.         ...  0.         -0.4308036\n",
      "  -0.5612956 ]]\n",
      "28.4 µs ± 1.66 µs per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "@jax.jit\n",
    "def vjpcfun5(g_aff):\n",
    "    g_buf = jnp.zeros((nn, 255))\n",
    "    # buffer[jnp.tile(jnp.arange(nn),(nn,1)),lengths] (84,84)\n",
    "    # jnp.sum(weights*b[], axis=1)\n",
    "    return g_buf.at[nr, lengths].add(g_aff[:,None] * weights)\n",
    "\n",
    "print(vjpcfun5(g_aff1))\n",
    "%timeit vjpcfun5(g_aff1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "b6525d90",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-20T14:46:48.499398Z",
     "start_time": "2022-12-20T14:46:48.484157Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g__ = np.zeros(nn)\n",
    "g__[0] = 1.0\n",
    "(np.abs(jnp.dot(g__, J))>0).sum() == 84"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "49cb1195",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-20T14:48:23.150846Z",
     "start_time": "2022-12-20T14:48:23.042090Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x28f490070>"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "imshow(g__[:,None]*weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "a5cbac88",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-20T14:55:48.583445Z",
     "start_time": "2022-12-20T14:55:48.520402Z"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "dot_general requires contracting dimensions to have the same shape, got (1,) and (84,).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[221], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m g_buf \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((nn, \u001b[38;5;241m255\u001b[39m))\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# buffer[jnp.tile(jnp.arange(nn),(nn,1)),lengths] (84,84)\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# jnp.sum(weights*b[], axis=1)\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m g_buf[np\u001b[38;5;241m.\u001b[39mtile(np\u001b[38;5;241m.\u001b[39marange(nn),(nn,\u001b[38;5;241m1\u001b[39m)), lengths] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[43mg__\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m]\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m)[:,\u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[1;32m      6\u001b[0m plot(jnp\u001b[38;5;241m.\u001b[39mdot(g__, J)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m), g_buf\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/nfjax-Y-MGz7Lr/lib/python3.10/site-packages/jax/_src/numpy/lax_numpy.py:4948\u001b[0m, in \u001b[0;36m_defer_to_unrecognized_arg.<locals>.deferring_binary_op\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m   4946\u001b[0m args \u001b[38;5;241m=\u001b[39m (other, \u001b[38;5;28mself\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m swap \u001b[38;5;28;01melse\u001b[39;00m (\u001b[38;5;28mself\u001b[39m, other)\n\u001b[1;32m   4947\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(other, _accepted_binop_types):\n\u001b[0;32m-> 4948\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbinary_op\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4949\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(other, _rejected_binop_types):\n\u001b[1;32m   4950\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munsupported operand type(s) for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mopchar\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4951\u001b[0m                   \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(args[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(args[\u001b[38;5;241m1\u001b[39m])\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "    \u001b[0;31m[... skipping hidden 12 frame]\u001b[0m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/nfjax-Y-MGz7Lr/lib/python3.10/site-packages/jax/_src/numpy/lax_numpy.py:2987\u001b[0m, in \u001b[0;36mmatmul\u001b[0;34m(a, b, precision)\u001b[0m\n\u001b[1;32m   2985\u001b[0m a \u001b[38;5;241m=\u001b[39m lax\u001b[38;5;241m.\u001b[39msqueeze(a, \u001b[38;5;28mtuple\u001b[39m(a_squeeze))\n\u001b[1;32m   2986\u001b[0m b \u001b[38;5;241m=\u001b[39m lax\u001b[38;5;241m.\u001b[39msqueeze(b, \u001b[38;5;28mtuple\u001b[39m(b_squeeze))\n\u001b[0;32m-> 2987\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mlax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot_general\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2988\u001b[0m \u001b[43m  \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mndim\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mndim\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mb_is_mat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43ma_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb_batch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2989\u001b[0m \u001b[43m  \u001b[49m\u001b[43mprecision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprecision\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2990\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m lax\u001b[38;5;241m.\u001b[39mtranspose(out, perm)\n",
      "    \u001b[0;31m[... skipping hidden 7 frame]\u001b[0m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/nfjax-Y-MGz7Lr/lib/python3.10/site-packages/jax/_src/lax/lax.py:2530\u001b[0m, in \u001b[0;36m_dot_general_shape_rule\u001b[0;34m(lhs, rhs, dimension_numbers, precision, preferred_element_type)\u001b[0m\n\u001b[1;32m   2527\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m core\u001b[38;5;241m.\u001b[39msymbolic_equal_shape(lhs_contracting_shape, rhs_contracting_shape):\n\u001b[1;32m   2528\u001b[0m   msg \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdot_general requires contracting dimensions to have the same \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2529\u001b[0m          \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 2530\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg\u001b[38;5;241m.\u001b[39mformat(lhs_contracting_shape, rhs_contracting_shape))\n\u001b[1;32m   2532\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _dot_general_shape_computation(lhs\u001b[38;5;241m.\u001b[39mshape, rhs\u001b[38;5;241m.\u001b[39mshape, dimension_numbers)\n",
      "\u001b[0;31mTypeError\u001b[0m: dot_general requires contracting dimensions to have the same shape, got (1,) and (84,)."
     ]
    }
   ],
   "source": [
    "g_buf = np.zeros((nn, 255))\n",
    "# buffer[jnp.tile(jnp.arange(nn),(nn,1)),lengths] (84,84)\n",
    "# jnp.sum(weights*b[], axis=1)\n",
    "g_buf[np.tile(np.arange(nn),(nn,1)), lengths] += (g__[:,None]  @ weights)[:,None]\n",
    "\n",
    "plot(jnp.dot(g__, J).reshape(-1), g_buf.reshape(-1), '.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f921c2af",
   "metadata": {},
   "source": [
    "let's break it down then, how to reverse mode `buffer[jnp.tile(jnp.arange(nn),(nn,1)),lengths]`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c622618",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-20T22:26:02.397356Z",
     "start_time": "2022-12-20T22:26:02.325522Z"
    }
   },
   "outputs": [],
   "source": [
    "def foo(buffer):\n",
    "    return jnp.sum(buffer[jnp.tile(jnp.arange(nn),(nn,1)),lengths])\n",
    "\n",
    "gfoo1 = jax.grad(foo)\n",
    "\n",
    "def gfoo2(buffer):\n",
    "    return jnp.zeros_like(buffer).at[jnp.tile(jnp.arange(nn),(nn,1)),lengths].add(1)\n",
    "\n",
    "np.testing.assert_allclose(gfoo1(buffer), gfoo2(buffer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "d3e4cb8d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-20T22:31:52.755225Z",
     "start_time": "2022-12-20T22:31:51.613875Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[    0.,     0.,     0., ...,     0.,  4956.,  2436.],\n",
       "       [ 8319.,    85.,     0., ...,     0.,     0.,  6553.],\n",
       "       [    0.,  1010.,     0., ...,     0.,     0.,     0.],\n",
       "       ...,\n",
       "       [  501.,     0.,     0., ...,  6213.,     0.,     0.],\n",
       "       [    0.,     0.,  3526., ...,  3694.,     0.,     0.],\n",
       "       [    0.,     0.,     0., ...,     0.,  8650., 11674.]],      dtype=float32)"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def foo(buffer):\n",
    "    return buffer[jnp.tile(jnp.arange(nn),(nn,1)),lengths]\n",
    "\n",
    "g = jnp.r_[:84*84]\n",
    "J_foo = jax.jacrev(foo)(buffer).reshape((-1, nn, 255))\n",
    "\n",
    "vjp_foo = jnp.sum(g[:,None,None] * J_foo, axis=0)\n",
    "\n",
    "vjp_foo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "e5fc37f2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-20T22:32:16.027512Z",
     "start_time": "2022-12-20T22:32:16.005275Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[    0.,     0.,     0., ...,     0.,  4956.,  2436.],\n",
       "       [ 8319.,    85.,     0., ...,     0.,     0.,  6553.],\n",
       "       [    0.,  1010.,     0., ...,     0.,     0.,     0.],\n",
       "       ...,\n",
       "       [  501.,     0.,     0., ...,  6213.,     0.,     0.],\n",
       "       [    0.,     0.,  3526., ...,  3694.,     0.,     0.],\n",
       "       [    0.,     0.,     0., ...,     0.,  8650., 11674.]],      dtype=float32)"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def vjp_foo2(g, buffer):\n",
    "    return jnp.zeros_like(buffer).at[jnp.tile(jnp.arange(nn),(nn,1)),lengths].add(g.reshape((nn, nn)))\n",
    "\n",
    "np.testing.assert_allclose(vjp_foo, vjp_foo2(g, buffer))\n",
    "vjp_foo2(g, buffer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5455e0e3",
   "metadata": {},
   "source": [
    "and the sum over row?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "743fd57f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-20T22:25:05.011534Z",
     "start_time": "2022-12-20T22:25:04.984725Z"
    }
   },
   "outputs": [],
   "source": [
    "def sum_rows(A):\n",
    "    return jnp.sum(A, axis=1)\n",
    "\n",
    "g_sum_rows1 = jax.jacrev(sum_rows)\n",
    "\n",
    "def vjp_sum_rows2(g,A):\n",
    "    return jnp.tile(g[:,None],(1,A.shape[1]))\n",
    "\n",
    "np.testing.assert_allclose(jnp.r_[:nn] @ g_sum_rows1(buffer),\n",
    "                           vjp_sum_rows2(jnp.r_[:nn], buffer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b69032",
   "metadata": {},
   "source": [
    "Let's try to combine the two, with weights too,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "d3536438",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-20T22:45:08.138763Z",
     "start_time": "2022-12-20T22:44:55.115673Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.3 µs ± 21.1 ns per loop (mean ± std. dev. of 7 runs, 100,000 loops each)\n",
      "26.3 µs ± 81 ns per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "ns = jnp.tile(jnp.arange(nn),(nn,1))\n",
    "\n",
    "def foo(buffer):\n",
    "    b = buffer[ns,lengths]\n",
    "    return jnp.sum(weights*b, axis=1)  # what is rev pass for this??\n",
    "\n",
    "gfoo1 = jax.jacrev(foo)\n",
    "\n",
    "def vjpfoo(g,buffer):\n",
    "    gb = jnp.tile(g[:,None],(1,nn)) # rev of sum(b,axis=1)\n",
    "    gbuf = jnp.zeros_like(buffer).at[ns,lengths.T].add(weights.T*gb) # lengths.T?\n",
    "    return gbuf \n",
    "\n",
    "gaff = np.r_[:nn]\n",
    "np.testing.assert_allclose(gaff@gfoo1(buffer), vjpfoo(gaff,buffer), 1e-5, 1e-5)\n",
    "\n",
    "np.testing.assert_allclose(foo(buffer), aff1, 1e-5, 1e-5)\n",
    "\n",
    "ff = jax.jit(foo)\n",
    "vf = jax.jit(vjpfoo)\n",
    "%timeit ff(buffer)\n",
    "%timeit vf(gaff,buffer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70490885",
   "metadata": {},
   "source": [
    "So now we've got a connectome impl which matches our naive impl but has an expected autodiff perf (~2x slower)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
